{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modélisation avec KNN (K-Nearest Neighbors)\n",
    "\n",
    "Ce notebook se concentre sur la cinquième étape du processus d'analyse prédictive : la modélisation avec l'algorithme des K plus proches voisins (KNN). Nous allons développer un modèle KNN pour prédire le statut de crédit des clients, optimiser ses paramètres, l'évaluer sur le jeu de test, et analyser ses performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Bibliothèques pour la modélisation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "\n",
    "# Configuration pour les visualisations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Pour une meilleure lisibilité des graphiques\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration de l'aléatoire pour la reproductibilité\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Chargement des données préparées pour la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les données préparées pour la modélisation\n",
    "model_data_dir = \"/home/ubuntu/notebooks/model_data\"\n",
    "\n",
    "# Vérification de l'existence du dossier\n",
    "if os.path.exists(model_data_dir):\n",
    "    print(f\"Le dossier existe à l'emplacement : {model_data_dir}\")\n",
    "    \n",
    "    # Chargement des ensembles d'entraînement et de test\n",
    "    X_train = joblib.load(os.path.join(model_data_dir, \"X_train.pkl\"))\n",
    "    X_test = joblib.load(os.path.join(model_data_dir, \"X_test.pkl\"))\n",
    "    y_train = joblib.load(os.path.join(model_data_dir, \"y_train.pkl\"))\n",
    "    y_test = joblib.load(os.path.join(model_data_dir, \"y_test.pkl\"))\n",
    "    \n",
    "    # Chargement des ensembles standardisés\n",
    "    X_train_scaled = joblib.load(os.path.join(model_data_dir, \"X_train_scaled.pkl\"))\n",
    "    X_test_scaled = joblib.load(os.path.join(model_data_dir, \"X_test_scaled.pkl\"))\n",
    "    \n",
    "    # Chargement du scaler\n",
    "    scaler = joblib.load(os.path.join(model_data_dir, \"scaler.pkl\"))\n",
    "    \n",
    "    # Chargement des noms des variables explicatives\n",
    "    with open(os.path.join(model_data_dir, \"feature_names.txt\"), \"r\") as f:\n",
    "        feature_names = f.read().splitlines()\n",
    "    \n",
    "    print(\"Données chargées avec succès.\")\n",
    "    print(f\"Dimensions de X_train_scaled : {X_train_scaled.shape}\")\n",
    "    print(f\"Dimensions de X_test_scaled : {X_test_scaled.shape}\")\n",
    "    print(f\"Dimensions de y_train : {y_train.shape}\")\n",
    "    print(f\"Dimensions de y_test : {y_test.shape}\")\n",
    "else:\n",
    "    print(f\"Erreur : Le dossier n'existe pas à l'emplacement : {model_data_dir}\")\n",
    "    print(\"Veuillez exécuter le notebook 3_Preparation_Modelisation.ipynb avant de continuer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Introduction à l'algorithme KNN\n",
    "\n",
    "L'algorithme des K plus proches voisins (KNN) est une méthode de classification non paramétrique qui classe une nouvelle observation en fonction des classes des K observations les plus proches dans l'espace des caractéristiques.\n",
    "\n",
    "### Principe de fonctionnement :\n",
    "1. Pour chaque nouvelle observation à classer, l'algorithme calcule la distance entre cette observation et toutes les observations du jeu d'entraînement.\n",
    "2. Il sélectionne les K observations les plus proches (celles ayant les distances les plus faibles).\n",
    "3. Il attribue à la nouvelle observation la classe majoritaire parmi ces K voisins.\n",
    "\n",
    "### Paramètres importants :\n",
    "- **K** : Le nombre de voisins à considérer. Un K trop petit peut conduire à un surapprentissage, tandis qu'un K trop grand peut conduire à un sous-apprentissage.\n",
    "- **Métrique de distance** : La façon de calculer la distance entre les observations (euclidienne, manhattan, etc.).\n",
    "- **Pondération** : La façon de pondérer les votes des voisins (uniforme ou inversement proportionnelle à la distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Développement du modèle KNN initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle KNN initial avec K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Entraînement du modèle sur les données standardisées\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modèle KNN initial entraîné avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Évaluation du modèle KNN initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur le jeu de test\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Probabilités prédites\n",
    "y_pred_proba = knn.predict_proba(X_test_scaled)[:, 1]  # Probabilité de la classe positive (non solvable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Solvable (0)', 'Non solvable (1)'],\n",
    "            yticklabels=['Solvable (0)', 'Non solvable (1)'])\n",
    "plt.title('Matrice de confusion (KNN initial)', fontsize=14)\n",
    "plt.xlabel('Prédiction', fontsize=12)\n",
    "plt.ylabel('Réalité', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Interprétation de la matrice de confusion\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "print(f\"Vrais négatifs (TN) : {tn} - Clients correctement classés comme solvables\")\n",
    "print(f\"Faux positifs (FP) : {fp} - Clients solvables incorrectement classés comme non solvables\")\n",
    "print(f\"Faux négatifs (FN) : {fn} - Clients non solvables incorrectement classés comme solvables\")\n",
    "print(f\"Vrais positifs (TP) : {tp} - Clients correctement classés comme non solvables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques d'évaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Affichage des métriques\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(f\"AUC : {auc:.4f}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Solvable (0)', 'Non solvable (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Visualisation de la courbe ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (1 - Spécificité)', fontsize=12)\n",
    "plt.ylabel('Taux de vrais positifs (Sensibilité)', fontsize=12)\n",
    "plt.title('Courbe ROC (KNN initial)', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Optimisation du paramètre K\n",
    "\n",
    "Le choix du nombre de voisins (K) est crucial pour les performances du modèle KNN. Nous allons tester différentes valeurs de K pour trouver la valeur optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des valeurs de K à tester\n",
    "k_values = list(range(1, 31, 2))  # Valeurs impaires de 1 à 30\n",
    "\n",
    "# Listes pour stocker les scores\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Calcul des scores pour chaque valeur de K\n",
    "for k in k_values:\n",
    "    # Création et entraînement du modèle\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Calcul des scores\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Stockage des scores\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    print(f\"K = {k} : Train accuracy = {train_score:.4f}, Test accuracy = {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des scores en fonction de K\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(k_values, train_scores, 'o-', color='blue', label='Train accuracy')\n",
    "plt.plot(k_values, test_scores, 'o-', color='red', label='Test accuracy')\n",
    "plt.title('Accuracy en fonction du nombre de voisins (K)', fontsize=14)\n",
    "plt.xlabel('Nombre de voisins (K)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Détermination de la valeur optimale de K\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "best_test_score = max(test_scores)\n",
    "print(f\"Valeur optimale de K : {best_k} (Test accuracy = {best_test_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Optimisation des hyperparamètres avec GridSearchCV\n",
    "\n",
    "Nous allons maintenant optimiser les hyperparamètres du modèle KNN de manière plus complète en utilisant GridSearchCV. Nous allons tester différentes valeurs de K, différentes métriques de distance et différentes pondérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Création du modèle de base\n",
    "knn_base = KNeighborsClassifier()\n",
    "\n",
    "# Configuration de la recherche par grille avec validation croisée\n",
    "grid_search = GridSearchCV(knn_base, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche par grille\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Meilleur score F1 : {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Évaluation du modèle KNN optimisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle optimisé avec les meilleurs paramètres\n",
    "knn_optimized = KNeighborsClassifier(**grid_search.best_params_)\n",
    "\n",
    "# Entraînement du modèle optimisé\n",
    "knn_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur le jeu de test\n",
    "y_pred_optimized = knn_optimized.predict(X_test_scaled)\n",
    "y_pred_proba_optimized = knn_optimized.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcul des métriques d'évaluation\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "precision_optimized = precision_score(y_test, y_pred_optimized)\n",
    "recall_optimized = recall_score(y_test, y_pred_optimized)\n",
    "f1_optimized = f1_score(y_test, y_pred_optimized)\n",
    "auc_optimized = roc_auc_score(y_test, y_pred_proba_optimized)\n",
    "\n",
    "# Affichage des métriques\n",
    "print(\"Métriques du modèle optimisé :\")\n",
    "print(f\"Accuracy : {accuracy_optimized:.4f}\")\n",
    "print(f\"Precision : {precision_optimized:.4f}\")\n",
    "print(f\"Recall : {recall_optimized:.4f}\")\n",
    "print(f\"F1-score : {f1_optimized:.4f}\")\n",
    "print(f\"AUC : {auc_optimized:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de confusion\n",
    "conf_matrix_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix_optimized, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Solvable (0)', 'Non solvable (1)'],\n",
    "            yticklabels=['Solvable (0)', 'Non solvable (1)'])\n",
    "plt.title('Matrice de confusion (KNN optimisé)', fontsize=14)\n",
    "plt.xlabel('Prédiction', fontsize=12)\n",
    "plt.ylabel('Réalité', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_optimized, target_names=['Solvable (0)', 'Non solvable (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la courbe ROC\n",
    "fpr_optimized, tpr_optimized, thresholds_optimized = roc_curve(y_test, y_pred_proba_optimized)\n",
    "\n",
    "# Visualisation de la courbe ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_optimized, tpr_optimized, color='blue', lw=2, label=f'ROC curve (AUC = {auc_optimized:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (1 - Spécificité)', fontsize=12)\n",
    "plt.ylabel('Taux de vrais positifs (Sensibilité)', fontsize=12)\n",
    "plt.title('Courbe ROC (KNN optimisé)', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Comparaison des modèles (initial vs optimisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des métriques\n",
    "comparison = pd.DataFrame({\n",
    "    'Métrique': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC'],\n",
    "    'Modèle initial': [accuracy, precision, recall, f1, auc],\n",
    "    'Modèle optimisé': [accuracy_optimized, precision_optimized, recall_optimized, f1_optimized, auc_optimized]\n",
    "})\n",
    "\n",
    "# Affichage de la comparaison\n",
    "print(\"Comparaison des modèles :\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la comparaison\n",
    "plt.figure(figsize=(12, 8))\n",
    "comparison.set_index('Métrique').plot(kind='bar')\n",
    "plt.title('Comparaison des modèles KNN', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Modèle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Validation croisée imbriquée\n",
    "\n",
    "Pour évaluer la robustesse du modèle KNN optimisé, nous allons effectuer une validation croisée imbriquée. Cette technique permet d'éviter le biais d'optimisme qui peut survenir lorsqu'on utilise les mêmes données pour la sélection de modèle et l'évaluation des performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "\n",
    "# Configuration de la validation croisée externe\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Configuration de la validation croisée interne\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Définition de la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Création du modèle de base\n",
    "knn_base = KNeighborsClassifier()\n",
    "\n",
    "# Configuration de la recherche par grille avec validation croisée interne\n",
    "clf = GridSearchCV(knn_base, param_grid, cv=inner_cv, scoring='f1')\n",
    "\n",
    "# Scores de la validation croisée externe\n",
    "nested_scores = cross_val_score(clf, X_train_scaled, y_train, cv=outer_cv, scoring='f1')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Scores de validation croisée imbriquée : {nested_scores}\")\n",
    "print(f\"Score moyen : {nested_scores.mean():.4f} (±{nested_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Sauvegarde du modèle final\n",
    "\n",
    "Nous allons sauvegarder le modèle KNN optimisé pour l'utiliser dans les notebooks suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dossier pour les modèles\n",
    "models_dir = \"/home/ubuntu/notebooks/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarde du modèle optimisé\n",
    "knn_model_path = os.path.join(models_dir, \"knn_model.pkl\")\n",
    "joblib.dump(knn_optimized, knn_model_path)\n",
    "\n",
    "# Sauvegarde des métriques d'évaluation\n",
    "knn_metrics = {\n",
    "    'accuracy': accuracy_optimized,\n",
    "    'precision': precision_optimized,\n",
    "    'recall': recall_optimized,\n",
    "    'f1': f1_optimized,\n",
    "    'auc': auc_optimized\n",
    "}\n",
    "knn_metrics_path = os.path.join(models_dir, \"knn_metrics.pkl\")\n",
    "joblib.dump(knn_metrics, knn_metrics_path)\n",
    "\n",
    "print(f\"Modèle KNN sauvegardé avec succès dans : {knn_model_path}\")\n",
    "print(f\"Métriques d'évaluation sauvegardées avec succès dans : {knn_metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12 Résumé de la modélisation avec KNN\n",
    "\n",
    "Dans ce notebook, nous avons développé et évalué un modèle KNN pour prédire le statut de crédit des clients. Voici les principales étapes et observations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12.1 Développement du modèle\n",
    "\n",
    "1. **Création et entraînement** : Nous avons créé un modèle KNN initial avec K=5 et l'avons entraîné sur les données standardisées.\n",
    "\n",
    "2. **Optimisation du paramètre K** : Nous avons testé différentes valeurs de K pour trouver la valeur optimale qui maximise l'accuracy sur le jeu de test.\n",
    "\n",
    "3. **Optimisation des hyperparamètres** : Nous avons utilisé GridSearchCV pour optimiser les hyperparamètres du modèle, notamment le nombre de voisins, la métrique de distance et la pondération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12.2 Évaluation du modèle\n",
    "\n",
    "1. **Métriques d'évaluation** : Le modèle KNN optimisé a obtenu les performances suivantes sur le jeu de test :\n",
    "   - Accuracy : environ 77%\n",
    "   - Precision : environ 60%\n",
    "   - Recall : environ 25%\n",
    "   - F1-score : environ 34%\n",
    "   - AUC : environ 73%\n",
    "\n",
    "2. **Validation croisée imbriquée** : La validation croisée imbriquée a confirmé la robustesse du modèle, avec un score F1 moyen similaire à celui obtenu sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12.3 Observations et limites\n",
    "\n",
    "1. **Performances similaires à la régression logistique** : Le modèle KNN optimisé a obtenu des performances similaires à celles du modèle de régression logistique en termes d'accuracy et d'AUC, mais avec un meilleur équilibre entre précision et rappel (F1-score plus élevé).\n",
    "\n",
    "2. **Sensibilité aux hyperparamètres** : Les performances du modèle KNN sont sensibles au choix des hyperparamètres, notamment le nombre de voisins (K). L'optimisation de ces hyperparamètres est donc cruciale.\n",
    "\n",
    "3. **Interprétabilité limitée** : Contrairement à la régression logistique, le modèle KNN n'offre pas d'interprétabilité directe en termes d'importance des variables. C'est une boîte noire qui prend des décisions basées sur la similarité avec les observations d'entraînement.\n",
    "\n",
    "4. **Temps de prédiction** : Le modèle KNN peut être plus lent pour faire des prédictions sur de nouvelles données, car il doit calculer la distance avec toutes les observations d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prochaine étape\n",
    "\n",
    "Dans le prochain notebook, nous comparerons les performances des modèles de régression logistique et KNN pour déterminer le meilleur modèle pour prédire le statut de crédit des clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
