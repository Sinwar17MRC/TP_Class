{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modélisation avec Régression Logistique\n",
    "\n",
    "Ce notebook se concentre sur la quatrième étape du processus d'analyse prédictive : la modélisation avec régression logistique. Nous allons développer un modèle de régression logistique pour prédire le statut de crédit des clients, l'évaluer sur le jeu de test, et analyser ses performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Bibliothèques pour la modélisation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Configuration pour les visualisations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Pour une meilleure lisibilité des graphiques\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration de l'aléatoire pour la reproductibilité\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Chargement des données préparées pour la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les données préparées pour la modélisation\n",
    "model_data_dir = \"/home/ubuntu/notebooks/model_data\"\n",
    "\n",
    "# Vérification de l'existence du dossier\n",
    "if os.path.exists(model_data_dir):\n",
    "    print(f\"Le dossier existe à l'emplacement : {model_data_dir}\")\n",
    "    \n",
    "    # Chargement des ensembles d'entraînement et de test\n",
    "    X_train = joblib.load(os.path.join(model_data_dir, \"X_train.pkl\"))\n",
    "    X_test = joblib.load(os.path.join(model_data_dir, \"X_test.pkl\"))\n",
    "    y_train = joblib.load(os.path.join(model_data_dir, \"y_train.pkl\"))\n",
    "    y_test = joblib.load(os.path.join(model_data_dir, \"y_test.pkl\"))\n",
    "    \n",
    "    # Chargement des ensembles standardisés\n",
    "    X_train_scaled = joblib.load(os.path.join(model_data_dir, \"X_train_scaled.pkl\"))\n",
    "    X_test_scaled = joblib.load(os.path.join(model_data_dir, \"X_test_scaled.pkl\"))\n",
    "    \n",
    "    # Chargement du scaler\n",
    "    scaler = joblib.load(os.path.join(model_data_dir, \"scaler.pkl\"))\n",
    "    \n",
    "    # Chargement des noms des variables explicatives\n",
    "    with open(os.path.join(model_data_dir, \"feature_names.txt\"), \"r\") as f:\n",
    "        feature_names = f.read().splitlines()\n",
    "    \n",
    "    print(\"Données chargées avec succès.\")\n",
    "    print(f\"Dimensions de X_train_scaled : {X_train_scaled.shape}\")\n",
    "    print(f\"Dimensions de X_test_scaled : {X_test_scaled.shape}\")\n",
    "    print(f\"Dimensions de y_train : {y_train.shape}\")\n",
    "    print(f\"Dimensions de y_test : {y_test.shape}\")\n",
    "else:\n",
    "    print(f\"Erreur : Le dossier n'existe pas à l'emplacement : {model_data_dir}\")\n",
    "    print(\"Veuillez exécuter le notebook 3_Preparation_Modelisation.ipynb avant de continuer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des noms des variables explicatives\n",
    "print(\"Variables explicatives :\")\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print(f\"{i+1}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Développement du modèle de régression logistique\n",
    "\n",
    "La régression logistique est un algorithme de classification linéaire qui estime la probabilité qu'une instance appartienne à une classe particulière. C'est un bon point de départ pour les problèmes de classification binaire comme le nôtre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Création et entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle de régression logistique\n",
    "# Nous utilisons la régularisation L2 (ridge) par défaut\n",
    "# Le paramètre C contrôle la force de la régularisation (plus C est petit, plus la régularisation est forte)\n",
    "# class_weight='balanced' permet de gérer le déséquilibre des classes\n",
    "logreg = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# Entraînement du modèle sur les données standardisées\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modèle de régression logistique entraîné avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Analyse des coefficients du modèle\n",
    "\n",
    "Les coefficients de la régression logistique indiquent l'importance et la direction de l'influence de chaque variable sur la probabilité de la classe positive (non solvable dans notre cas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des coefficients du modèle\n",
    "coefficients = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coefficient': logreg.coef_[0]\n",
    "})\n",
    "\n",
    "# Tri des coefficients par valeur absolue décroissante\n",
    "coefficients['Abs_Coefficient'] = abs(coefficients['Coefficient'])\n",
    "coefficients = coefficients.sort_values('Abs_Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Affichage des coefficients\n",
    "print(\"Coefficients du modèle de régression logistique :\")\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Coefficient', y='Variable', data=coefficients)\n",
    "plt.title('Coefficients du modèle de régression logistique', fontsize=14)\n",
    "plt.xlabel('Coefficient', fontsize=12)\n",
    "plt.ylabel('Variable', fontsize=12)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Interprétation des coefficients\n",
    "\n",
    "Analysons les coefficients pour comprendre l'influence de chaque variable sur la probabilité qu'un client soit non solvable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interprétation des coefficients\n",
    "interpretation = pd.DataFrame({\n",
    "    'Variable': coefficients['Variable'],\n",
    "    'Coefficient': coefficients['Coefficient'],\n",
    "    'Influence': ['Augmente la probabilité de non-solvabilité' if coef > 0 else 'Diminue la probabilité de non-solvabilité' \n",
    "                 for coef in coefficients['Coefficient']],\n",
    "    'Importance': coefficients['Abs_Coefficient']\n",
    "})\n",
    "\n",
    "# Affichage de l'interprétation\n",
    "print(\"Interprétation des coefficients :\")\n",
    "interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Évaluation du modèle sur le jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Prédictions sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur le jeu de test\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Probabilités prédites\n",
    "y_pred_proba = logreg.predict_proba(X_test_scaled)[:, 1]  # Probabilité de la classe positive (non solvable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Solvable (0)', 'Non solvable (1)'],\n",
    "            yticklabels=['Solvable (0)', 'Non solvable (1)'])\n",
    "plt.title('Matrice de confusion', fontsize=14)\n",
    "plt.xlabel('Prédiction', fontsize=12)\n",
    "plt.ylabel('Réalité', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Interprétation de la matrice de confusion\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "print(f\"Vrais négatifs (TN) : {tn} - Clients correctement classés comme solvables\")\n",
    "print(f\"Faux positifs (FP) : {fp} - Clients solvables incorrectement classés comme non solvables\")\n",
    "print(f\"Faux négatifs (FN) : {fn} - Clients non solvables incorrectement classés comme solvables\")\n",
    "print(f\"Vrais positifs (TP) : {tp} - Clients correctement classés comme non solvables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Métriques d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques d'évaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des métriques\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Solvable (0)', 'Non solvable (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 Courbe ROC et AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calcul de l'AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Visualisation de la courbe ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs (1 - Spécificité)', fontsize=12)\n",
    "plt.ylabel('Taux de vrais positifs (Sensibilité)', fontsize=12)\n",
    "plt.title('Courbe ROC', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC : {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Validation croisée\n",
    "\n",
    "Pour évaluer la robustesse du modèle, nous allons effectuer une validation croisée à 5 plis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la validation croisée stratifiée\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Métriques à évaluer\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "cv_results = {}\n",
    "\n",
    "# Calcul des scores de validation croisée pour chaque métrique\n",
    "for metric in scoring:\n",
    "    cv_scores = cross_val_score(logreg, X_train_scaled, y_train, cv=cv, scoring=metric)\n",
    "    cv_results[metric] = cv_scores\n",
    "    print(f\"{metric}: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats de la validation croisée\n",
    "plt.figure(figsize=(12, 8))\n",
    "boxplot_data = [cv_results[metric] for metric in scoring]\n",
    "plt.boxplot(boxplot_data, labels=scoring, patch_artist=True)\n",
    "plt.title('Résultats de la validation croisée', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Optimisation des hyperparamètres\n",
    "\n",
    "Nous allons maintenant optimiser les hyperparamètres du modèle de régression logistique pour améliorer ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définition de la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],  # liblinear supporte à la fois l1 et l2\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Création du modèle de base\n",
    "logreg_base = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "# Configuration de la recherche par grille avec validation croisée\n",
    "grid_search = GridSearchCV(logreg_base, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Exécution de la recherche par grille\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Meilleur score F1 : {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle optimisé avec les meilleurs paramètres\n",
    "logreg_optimized = LogisticRegression(**grid_search.best_params_, random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "# Entraînement du modèle optimisé\n",
    "logreg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur le jeu de test\n",
    "y_pred_optimized = logreg_optimized.predict(X_test_scaled)\n",
    "y_pred_proba_optimized = logreg_optimized.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcul des métriques d'évaluation\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "precision_optimized = precision_score(y_test, y_pred_optimized)\n",
    "recall_optimized = recall_score(y_test, y_pred_optimized)\n",
    "f1_optimized = f1_score(y_test, y_pred_optimized)\n",
    "auc_optimized = roc_auc_score(y_test, y_pred_proba_optimized)\n",
    "\n",
    "# Affichage des métriques\n",
    "print(\"Métriques du modèle optimisé :\")\n",
    "print(f\"Accuracy : {accuracy_optimized:.4f}\")\n",
    "print(f\"Precision : {precision_optimized:.4f}\")\n",
    "print(f\"Recall : {recall_optimized:.4f}\")\n",
    "print(f\"F1-score : {f1_optimized:.4f}\")\n",
    "print(f\"AUC : {auc_optimized:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Comparaison des modèles (initial vs optimisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des métriques\n",
    "comparison = pd.DataFrame({\n",
    "    'Métrique': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC'],\n",
    "    'Modèle initial': [accuracy, precision, recall, f1, auc],\n",
    "    'Modèle optimisé': [accuracy_optimized, precision_optimized, recall_optimized, f1_optimized, auc_optimized]\n",
    "})\n",
    "\n",
    "# Affichage de la comparaison\n",
    "print(\"Comparaison des modèles :\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la comparaison\n",
    "plt.figure(figsize=(12, 8))\n",
    "comparison.set_index('Métrique').plot(kind='bar')\n",
    "plt.title('Comparaison des modèles', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Modèle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Sauvegarde du modèle final\n",
    "\n",
    "Nous allons sauvegarder le modèle optimisé pour l'utiliser dans les notebooks suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dossier pour les modèles\n",
    "models_dir = \"/home/ubuntu/notebooks/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarde du modèle optimisé\n",
    "logreg_model_path = os.path.join(models_dir, \"logreg_model.pkl\")\n",
    "joblib.dump(logreg_optimized, logreg_model_path)\n",
    "\n",
    "# Sauvegarde des métriques d'évaluation\n",
    "logreg_metrics = {\n",
    "    'accuracy': accuracy_optimized,\n",
    "    'precision': precision_optimized,\n",
    "    'recall': recall_optimized,\n",
    "    'f1': f1_optimized,\n",
    "    'auc': auc_optimized\n",
    "}\n",
    "logreg_metrics_path = os.path.join(models_dir, \"logreg_metrics.pkl\")\n",
    "joblib.dump(logreg_metrics, logreg_metrics_path)\n",
    "\n",
    "print(f\"Modèle de régression logistique sauvegardé avec succès dans : {logreg_model_path}\")\n",
    "print(f\"Métriques d'évaluation sauvegardées avec succès dans : {logreg_metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Résumé de la modélisation avec régression logistique\n",
    "\n",
    "Dans ce notebook, nous avons développé et évalué un modèle de régression logistique pour prédire le statut de crédit des clients. Voici les principales étapes et observations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.1 Développement du modèle\n",
    "\n",
    "1. **Création et entraînement** : Nous avons créé un modèle de régression logistique et l'avons entraîné sur les données standardisées.\n",
    "\n",
    "2. **Analyse des coefficients** : Nous avons analysé les coefficients du modèle pour comprendre l'influence de chaque variable sur la probabilité qu'un client soit non solvable.\n",
    "   - Les variables les plus importantes sont : loan_to_income, income, loan_amount, et age.\n",
    "   - Un ratio prêt/revenu élevé augmente la probabilité de non-solvabilité.\n",
    "   - Un revenu élevé diminue la probabilité de non-solvabilité.\n",
    "   - Un montant de prêt élevé augmente la probabilité de non-solvabilité.\n",
    "   - Un âge élevé diminue la probabilité de non-solvabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.2 Évaluation du modèle\n",
    "\n",
    "1. **Métriques d'évaluation** : Le modèle optimisé a obtenu les performances suivantes sur le jeu de test :\n",
    "   - Accuracy : environ 77%\n",
    "   - Precision : environ 83%\n",
    "   - Recall : environ 18%\n",
    "   - F1-score : environ 30%\n",
    "   - AUC : environ 73%\n",
    "\n",
    "2. **Validation croisée** : La validation croisée a confirmé la robustesse du modèle, avec des scores similaires sur les différents plis.\n",
    "\n",
    "3. **Optimisation des hyperparamètres** : Nous avons optimisé les hyperparamètres du modèle pour améliorer ses performances, notamment en ajustant le paramètre de régularisation C et le type de pénalité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.3 Observations et limites\n",
    "\n",
    "1. **Déséquilibre des classes** : Le modèle a une précision élevée mais un rappel faible, ce qui est typique des problèmes avec des classes déséquilibrées. Cela signifie qu'il est bon pour identifier les clients solvables, mais moins bon pour identifier les clients non solvables.\n",
    "\n",
    "2. **Compromis précision-rappel** : Selon le contexte métier, il peut être préférable de privilégier le rappel (identifier plus de clients non solvables au risque de refuser des crédits à des clients solvables) ou la précision (être plus sûr des clients identifiés comme non solvables au risque d'en manquer certains).\n",
    "\n",
    "3. **Interprétabilité** : La régression logistique offre une bonne interprétabilité, ce qui est un avantage important dans le domaine du crédit où les décisions doivent souvent être expliquées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prochaine étape\n",
    "\n",
    "Dans le prochain notebook, nous développerons et évaluerons un modèle KNN (K-Nearest Neighbors) pour prédire le statut de crédit des clients, puis nous comparerons ses performances avec celles du modèle de régression logistique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
